import os
from PIL import Image
import numpy as np
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F
from sklearn.metrics.pairwise import cosine_similarity

# ì‚¬ìš©ìë¡œë¶€í„° ì¶”ì²œê°’ê³¼ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥ë°›ìŒ
# ì‚¬ìš©ìë¡œë¶€í„° ì¶”ì²œê°’ì„ ì…ë ¥ë°›ìŒ, ì…ë ¥ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ì€ 0.985
similarity_threshold = float(input("ì¶”ì²œê°’ì€ 0.985 (ì—”í„° í‚¤ ì…ë ¥ ì‹œ ì¶”ì²œê°’): ") or "0.985")
images_folder = os.path.abspath(input("ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥: "))
root_dir = os.getcwd()

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ì €ì¥í•˜ê³  ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ì´ë™í•¨
os.chdir(root_dir)

# ëª¨ë¸ ë° ë³€ìˆ˜ ì´ˆê¸°í™”
model_name = "clip-vit-base32-torch"
supported_types = (".png", ".jpg", ".jpeg", ".webp")
img_count = len(os.listdir(images_folder))
batch_size = min(250, img_count)

# ë¹„ ì´ë¯¸ì§€ íŒŒì¼ ë° ì´ë¯¸ì§€ ì—†ëŠ” ê²½ìš° ì˜¤ë¥˜ ì¶œë ¥
non_images = [f for f in os.listdir(images_folder) if not f.lower().endswith(supported_types)]
if non_images:
    print(f"ğŸ’¥ Error: Found non-image file {non_images[0]} - This program doesn't allow it. Sorry! Use the Extras at the bottom to clean the folder.")
elif img_count == 0:
    print(f"ğŸ’¥ Error: No images found in {images_folder}")
else:
    print("\nğŸ’¿ Analyzing dataset...\n")
    # FiftyOne ë°ì´í„°ì…‹ ì´ˆê¸°í™”
    dataset = fo.Dataset()
    for image_file in os.listdir(images_folder):
        if image_file.lower().endswith(supported_types):
            image_path = os.path.join(images_folder, image_file)
            sample = fo.Sample(filepath=image_path)
            dataset.add_sample(sample)

    # FiftyOne Zoo ëª¨ë¸ ë¡œë“œ ë° ì„ë² ë”© ê³„ì‚°
    model = foz.load_zoo_model(model_name)
    embeddings = dataset.compute_embeddings(model, batch_size=batch_size)

    # ì´ë¯¸ì§€ ì„ë² ë”©ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê³  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
    batch_embeddings = np.array_split(embeddings, batch_size)
    similarity_matrices = []
    max_size_x = max(array.shape[0] for array in batch_embeddings)
    max_size_y = max(array.shape[1] for array in batch_embeddings)

    for i, batch_embedding in enumerate(batch_embeddings):
        similarity = cosine_similarity(batch_embedding)
        # 0ìœ¼ë¡œ íŒ¨ë”©í•˜ì—¬ np.concatenateì— ì‚¬ìš©
        padded_array = np.zeros((max_size_x, max_size_y))
        padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity
        similarity_matrices.append(padded_array)

    similarity_matrix = np.concatenate(similarity_matrices, axis=0)
    similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° ë° ìœ ì‚¬ë„ ì„ê³„ê°’ì— ë”°ë¼ ì´ë¯¸ì§€ ë§¤ì¹­
    similarity_matrix = cosine_similarity(embeddings)
    similarity_matrix -= np.identity(len(similarity_matrix))

    dataset.match(F("max_similarity") > similarity_threshold)
    dataset.tags = ["delete", "has_duplicates"]

    id_map = [s.id for s in dataset.select_fields(["id"])]
    samples_to_remove = set()
    samples_to_keep = set()

    for idx, sample in enumerate(dataset):
        if sample.id not in samples_to_remove:
            # ë‘ ê°œì˜ ì¤‘ë³µëœ ì¸ìŠ¤í„´ìŠ¤ ì¤‘ ì²« ë²ˆì§¸ ì¸ìŠ¤í„´ìŠ¤ ìœ ì§€
            samples_to_keep.add(sample.id)
            
            dup_idxs = np.where(similarity_matrix[idx] > similarity_threshold)[0]

            for dup in dup_idxs:
                # ì²« ë²ˆì§¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìœ ì§€í–ˆìœ¼ë¯€ë¡œ ë‚˜ë¨¸ì§€ ì¤‘ë³µëœ í•­ëª©ì„ ëª¨ë‘ ì œê±°
                    samples_to_remove.add(id_map[dup])

            if len(dup_idxs) > 0:
                sample.tags.append("has_duplicates")
                sample.save()
        else:
            sample.tags.append("delete")
            sample.save()

    # FiftyOne ì•± ì‹¤í–‰ ë° ì‚¬ìš©ì ì§€ì¹¨ ì¶œë ¥
    sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset)
    for group in sidebar_groups[1:]:
        group.expanded = False
    dataset.app_config.sidebar_groups = sidebar_groups
    dataset.save()
    session = fo.launch_app(dataset)

    print("â— Wait a minute for the session to load. If it doesn't, read above.")
    print("â— When it's ready, you'll see a grid of your images.")
    print("â— On the left side enable \"sample tags\" to visualize the images marked for deletion.")
    print("â— You can mark your own images with the \"delete\" label by selecting them and pressing the tag icon at the top.")
    input("â­• When you're done, enter something here to save your changes: ")

    print("ğŸ’¾ Saving...")

    # ì‚­ì œí•  ì´ë¯¸ì§€ ì œê±° ë° ê²°ê³¼ ì €ì¥
    kys = [s for s in dataset if "delete" in s.tags]
    dataset.remove_samples(kys)
    os.mkdir(path=os.path.join(images_folder, "output"))
    OUTPUT = os.path.abspath(os.path.join(images_folder, "output"))
    dataset.export(export_dir=OUTPUT, dataset_type=fo.types.ImageDirectory)

    # ì„¸ì…˜ ë° ì•± ë‹«ê¸°
    session.refresh()
    fo.close_app()

    print(f"\nâœ… Removed {len(kys)} images from dataset. You now have {len(os.listdir(OUTPUT))} images.")

